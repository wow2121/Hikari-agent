package com.xiaoguang.assistant.domain.multimodal

import kotlinx.coroutines.Dispatchers
import kotlinx.coroutines.async
import kotlinx.coroutines.awaitAll
import kotlinx.coroutines.flow.MutableStateFlow
import kotlinx.coroutines.flow.StateFlow
import kotlinx.coroutines.flow.asStateFlow
import kotlinx.coroutines.sync.Mutex
import kotlinx.coroutines.sync.withLock
import kotlinx.coroutines.withContext
import java.time.LocalDateTime
import javax.inject.Inject
import javax.inject.Singleton
import kotlin.math.abs

/**
 * å¤šæ¨¡æ€èåˆå¼•æ“
 *
 * åŠŸèƒ½ï¼š
 * 1. è¯­éŸ³æƒ…æ„Ÿåˆ†æ - ä»è¯­éŸ³ç‰¹å¾æå–æƒ…æ„Ÿä¿¡æ¯ï¼ˆéŸ³è°ƒã€éŸ³é‡ã€è¯­é€Ÿç­‰ï¼‰
 * 2. é¢éƒ¨è¡¨æƒ…è¯†åˆ« - è¯†åˆ«é¢éƒ¨è¡¨æƒ…å¹¶æ˜ å°„åˆ°æƒ…æ„Ÿç»´åº¦
 * 3. æ¨¡æ€åŠ æƒèåˆ - æ ¹æ®ç½®ä¿¡åº¦èåˆå¤šä¸ªæ¨¡æ€çš„æƒ…æ„Ÿä¿¡æ¯
 *
 * åŸºäº Valence-Arousal äºŒç»´æƒ…æ„Ÿæ¨¡å‹
 */
@Singleton
class MultimodalFusionEngine @Inject constructor() {

    private val mutex = Mutex()
    private var config = FusionConfig()

    // èåˆå†å²è®°å½•
    private val _fusionHistory = MutableStateFlow<List<FusionRecord>>(emptyList())
    val fusionHistory: StateFlow<List<FusionRecord>> = _fusionHistory.asStateFlow()

    // ç»Ÿè®¡æ•°æ®
    private val _stats = MutableStateFlow(
        FusionStats(
            totalFusions = 0,
            voiceAnalysisCount = 0,
            faceAnalysisCount = 0,
            textAnalysisCount = 0,
            averageConfidence = 0f,
            lastFusionTime = null
        )
    )
    val stats: StateFlow<FusionStats> = _stats.asStateFlow()

    /**
     * èåˆå¤šæ¨¡æ€è¾“å…¥
     *
     * @param multimodalInput å¤šæ¨¡æ€è¾“å…¥æ•°æ®
     * @return èåˆåçš„æƒ…æ„Ÿç»“æœ
     */
    suspend fun fuseMultimodal(multimodalInput: MultimodalInput): Result<FusedEmotion> {
        return withContext(Dispatchers.Default) {
            try {
                mutex.withLock {
                    val modalityResults = mutableListOf<ModalityEmotionResult>()

                    // å¹¶è¡Œåˆ†æå„ä¸ªæ¨¡æ€
                    val analyses = listOf(
                        async { multimodalInput.voiceData?.let { analyzeVoice(it) } },
                        async { multimodalInput.faceData?.let { analyzeFace(it) } },
                        async { multimodalInput.textData?.let { analyzeText(it) } }
                    ).awaitAll()

                    // æ”¶é›†æœ‰æ•ˆç»“æœ
                    analyses.filterNotNull().forEach { modalityResults.add(it) }

                    if (modalityResults.isEmpty()) {
                        return@withContext Result.failure(
                            IllegalArgumentException("No valid modality data provided")
                        )
                    }

                    // èåˆå¤šä¸ªæ¨¡æ€
                    val fusedEmotion = fuseEmotions(modalityResults)

                    // è®°å½•èåˆç»“æœ
                    recordFusion(multimodalInput, fusedEmotion, modalityResults)

                    Result.success(fusedEmotion)
                }
            } catch (e: Exception) {
                Result.failure(e)
            }
        }
    }

    /**
     * åˆ†æè¯­éŸ³æƒ…æ„Ÿ
     *
     * @param voiceData è¯­éŸ³æ•°æ®ï¼ˆéŸ³é¢‘ç‰¹å¾ï¼‰
     * @return è¯­éŸ³æƒ…æ„Ÿåˆ†æç»“æœ
     */
    suspend fun analyzeVoice(voiceData: VoiceData): ModalityEmotionResult {
        return withContext(Dispatchers.Default) {
            // æå–è¯­éŸ³ç‰¹å¾
            val pitch = voiceData.pitch ?: 0f          // éŸ³è°ƒ (Hz)
            val volume = voiceData.volume ?: 0f        // éŸ³é‡ (dB)
            val speed = voiceData.speed ?: 1.0f        // è¯­é€Ÿ (å­—/ç§’)
            val jitter = voiceData.jitter ?: 0f        // å£°éŸ³é¢¤æŠ–åº¦

            // åŸºäºè¯­éŸ³ç‰¹å¾æ¨æ–­æƒ…æ„Ÿ
            // Valence (æ•ˆä»·): éŸ³è°ƒå’ŒéŸ³é‡çš„ç»¼åˆ
            val valence = calculateVoiceValence(pitch, volume, speed)

            // Arousal (å”¤é†’åº¦): éŸ³é‡å’Œè¯­é€Ÿçš„ç»¼åˆ
            val arousal = calculateVoiceArousal(volume, speed, jitter)

            // è®¡ç®—ç½®ä¿¡åº¦
            val confidence = calculateVoiceConfidence(voiceData)

            ModalityEmotionResult(
                modality = Modality.VOICE,
                valence = valence,
                arousal = arousal,
                confidence = confidence,
                rawFeatures = mapOf(
                    "pitch" to pitch,
                    "volume" to volume,
                    "speed" to speed,
                    "jitter" to jitter
                ),
                timestamp = LocalDateTime.now()
            )
        }
    }

    /**
     * åˆ†æé¢éƒ¨è¡¨æƒ…
     *
     * @param faceData é¢éƒ¨æ•°æ®ï¼ˆè¡¨æƒ…ç‰¹å¾ï¼‰
     * @return é¢éƒ¨è¡¨æƒ…åˆ†æç»“æœ
     */
    suspend fun analyzeFace(faceData: FaceData): ModalityEmotionResult {
        return withContext(Dispatchers.Default) {
            // é¢éƒ¨è¡¨æƒ…è¯†åˆ«
            val detectedExpression = detectExpression(faceData)

            // å°†è¡¨æƒ…æ˜ å°„åˆ° Valence-Arousal ç©ºé—´
            val (valence, arousal) = mapExpressionToEmotion(detectedExpression)

            // è®¡ç®—ç½®ä¿¡åº¦ï¼ˆåŸºäºé¢éƒ¨ç‰¹å¾æ¸…æ™°åº¦ï¼‰
            val confidence = calculateFaceConfidence(faceData, detectedExpression)

            ModalityEmotionResult(
                modality = Modality.FACE,
                valence = valence,
                arousal = arousal,
                confidence = confidence,
                rawFeatures = mapOf(
                    "expression_${detectedExpression.name.lowercase()}" to 1f,
                    "mouth_open" to (faceData.mouthOpen ?: 0f),
                    "eyebrow_raise" to (faceData.eyebrowRaise ?: 0f),
                    "eye_squint" to (faceData.eyeSquint ?: 0f)
                ),
                timestamp = LocalDateTime.now()
            )
        }
    }

    /**
     * åˆ†ææ–‡æœ¬æƒ…æ„Ÿï¼ˆè¾…åŠ©æ¨¡æ€ï¼‰
     *
     * @param textData æ–‡æœ¬æ•°æ®
     * @return æ–‡æœ¬æƒ…æ„Ÿåˆ†æç»“æœ
     */
    suspend fun analyzeText(textData: TextData): ModalityEmotionResult {
        return withContext(Dispatchers.Default) {
            val text = textData.content

            // ç®€åŒ–çš„æ–‡æœ¬æƒ…æ„Ÿåˆ†æï¼ˆå…³é”®è¯åŒ¹é…ï¼‰
            val positiveWords = listOf("å¼€å¿ƒ", "é«˜å…´", "å–œæ¬¢", "æ£’", "å¥½", "å“ˆå“ˆ", "ğŸ˜Š", "ğŸ˜„")
            val negativeWords = listOf("éš¾è¿‡", "ç”Ÿæ°”", "è®¨åŒ", "å·®", "ä¸å¥½", "ğŸ˜¢", "ğŸ˜ ")
            val excitedWords = listOf("æ¿€åŠ¨", "å…´å¥‹", "å“‡", "ï¼ï¼", "!!", "å¤ª", "è¶…")

            var valence = 0f
            var arousal = 0.3f  // åŸºçº¿å”¤é†’åº¦

            // è®¡ç®— Valence
            val positiveCount = positiveWords.count { text.contains(it) }
            val negativeCount = negativeWords.count { text.contains(it) }
            valence = ((positiveCount - negativeCount) / 5f).coerceIn(-1f, 1f)

            // è®¡ç®— Arousal
            val excitedCount = excitedWords.count { text.contains(it) }
            val exclamationCount = text.count { it == 'ï¼' || it == '!' }
            arousal = (0.3f + excitedCount * 0.2f + exclamationCount * 0.1f).coerceIn(0f, 1f)

            // ç½®ä¿¡åº¦è¾ƒä½ï¼ˆæ–‡æœ¬åˆ†æä¸å¦‚è¯­éŸ³å’Œé¢éƒ¨å‡†ç¡®ï¼‰
            val confidence = 0.6f

            ModalityEmotionResult(
                modality = Modality.TEXT,
                valence = valence,
                arousal = arousal,
                confidence = confidence,
                rawFeatures = mapOf(
                    "text_length" to text.length.toFloat(),
                    "positive_count" to positiveCount.toFloat(),
                    "negative_count" to negativeCount.toFloat(),
                    "excited_count" to excitedCount.toFloat()
                ),
                timestamp = LocalDateTime.now()
            )
        }
    }

    // ========== ç§æœ‰è¾…åŠ©æ–¹æ³• ==========

    /**
     * èåˆå¤šä¸ªæ¨¡æ€çš„æƒ…æ„Ÿç»“æœ
     */
    private fun fuseEmotions(modalityResults: List<ModalityEmotionResult>): FusedEmotion {
        // åŠ æƒå¹³å‡èåˆ
        var totalWeight = 0f
        var weightedValence = 0f
        var weightedArousal = 0f

        modalityResults.forEach { result ->
            val weight = calculateModalityWeight(result)
            weightedValence += result.valence * weight
            weightedArousal += result.arousal * weight
            totalWeight += weight
        }

        val fusedValence = if (totalWeight > 0) weightedValence / totalWeight else 0f
        val fusedArousal = if (totalWeight > 0) weightedArousal / totalWeight else 0.5f

        // è®¡ç®—èåˆç½®ä¿¡åº¦
        val fusedConfidence = calculateFusedConfidence(modalityResults)

        // æ˜ å°„åˆ°æƒ…æ„Ÿæ ‡ç­¾
        val emotionLabel = mapToEmotionLabel(fusedValence, fusedArousal)

        return FusedEmotion(
            valence = fusedValence,
            arousal = fusedArousal,
            confidence = fusedConfidence,
            emotionLabel = emotionLabel,
            modalityCount = modalityResults.size,
            modalityBreakdown = modalityResults,
            timestamp = LocalDateTime.now()
        )
    }

    /**
     * è®¡ç®—è¯­éŸ³ Valence
     */
    private fun calculateVoiceValence(pitch: Float, volume: Float, speed: Float): Float {
        // éŸ³è°ƒè¶Šé«˜ã€éŸ³é‡é€‚ä¸­ã€è¯­é€Ÿé€‚ä¸­ â†’ æ›´æ­£é¢
        val pitchScore = (pitch - 150f) / 150f  // æ ‡å‡†åŒ–ï¼Œå‡è®¾150Hzä¸ºåŸºå‡†
        val volumeScore = when {
            volume < 40f -> -0.2f    // éŸ³é‡å¤ªå°å¯èƒ½è¡¨ç¤ºæ¶ˆæ
            volume > 80f -> 0.1f     // éŸ³é‡å¤ªå¤§å¯èƒ½è¡¨ç¤ºæ¿€åŠ¨ä½†ä¸ä¸€å®šæ­£é¢
            else -> 0.3f             // é€‚ä¸­éŸ³é‡
        }
        val speedScore = when {
            speed < 2f -> -0.1f      // è¯­é€Ÿå¤ªæ…¢
            speed > 5f -> 0f         // è¯­é€Ÿå¤ªå¿«
            else -> 0.2f             // æ­£å¸¸è¯­é€Ÿ
        }

        return (pitchScore * 0.4f + volumeScore + speedScore).coerceIn(-1f, 1f)
    }

    /**
     * è®¡ç®—è¯­éŸ³ Arousal
     */
    private fun calculateVoiceArousal(volume: Float, speed: Float, jitter: Float): Float {
        // éŸ³é‡è¶Šå¤§ã€è¯­é€Ÿè¶Šå¿«ã€é¢¤æŠ–åº¦è¶Šé«˜ â†’ å”¤é†’åº¦è¶Šé«˜
        val volumeContribution = (volume / 100f).coerceIn(0f, 1f) * 0.4f
        val speedContribution = (speed / 6f).coerceIn(0f, 1f) * 0.4f
        val jitterContribution = jitter.coerceIn(0f, 1f) * 0.2f

        return (volumeContribution + speedContribution + jitterContribution).coerceIn(0f, 1f)
    }

    /**
     * è®¡ç®—è¯­éŸ³åˆ†æç½®ä¿¡åº¦
     */
    private fun calculateVoiceConfidence(voiceData: VoiceData): Float {
        var confidence = 0.7f  // åŸºç¡€ç½®ä¿¡åº¦

        // æ•°æ®å®Œæ•´æ€§
        val completeness = listOf(
            voiceData.pitch,
            voiceData.volume,
            voiceData.speed,
            voiceData.jitter
        ).count { it != null } / 4f

        confidence *= completeness

        // ä¿¡å·è´¨é‡
        voiceData.signalQuality?.let {
            confidence *= it
        }

        return confidence.coerceIn(0f, 1f)
    }

    /**
     * æ£€æµ‹é¢éƒ¨è¡¨æƒ…
     */
    private fun detectExpression(faceData: FaceData): FacialExpression {
        // åŸºäºé¢éƒ¨ç‰¹å¾æ£€æµ‹è¡¨æƒ…ï¼ˆç®€åŒ–ç‰ˆæœ¬ï¼‰
        val mouthOpen = faceData.mouthOpen ?: 0f
        val eyebrowRaise = faceData.eyebrowRaise ?: 0f
        val eyeSquint = faceData.eyeSquint ?: 0f
        val mouthCornerUp = faceData.mouthCornerUp ?: 0f
        val mouthCornerDown = faceData.mouthCornerDown ?: 0f

        return when {
            mouthCornerUp > 0.5f && eyeSquint < 0.3f -> FacialExpression.HAPPY
            mouthCornerDown > 0.5f -> FacialExpression.SAD
            eyebrowRaise > 0.6f && mouthOpen > 0.3f -> FacialExpression.SURPRISED
            eyeSquint > 0.6f && mouthCornerDown > 0.3f -> FacialExpression.ANGRY
            eyebrowRaise > 0.5f && mouthOpen < 0.2f -> FacialExpression.FEARFUL
            mouthCornerUp > 0.3f && eyeSquint > 0.5f -> FacialExpression.EXCITED
            else -> FacialExpression.NEUTRAL
        }
    }

    /**
     * å°†è¡¨æƒ…æ˜ å°„åˆ°æƒ…æ„Ÿç»´åº¦
     */
    private fun mapExpressionToEmotion(expression: FacialExpression): Pair<Float, Float> {
        // è¿”å› (Valence, Arousal)
        return when (expression) {
            FacialExpression.HAPPY -> Pair(0.8f, 0.6f)
            FacialExpression.SAD -> Pair(-0.7f, 0.3f)
            FacialExpression.ANGRY -> Pair(-0.8f, 0.9f)
            FacialExpression.FEARFUL -> Pair(-0.6f, 0.8f)
            FacialExpression.SURPRISED -> Pair(0.2f, 0.9f)
            FacialExpression.DISGUSTED -> Pair(-0.6f, 0.5f)
            FacialExpression.EXCITED -> Pair(0.7f, 0.9f)
            FacialExpression.NEUTRAL -> Pair(0f, 0.3f)
        }
    }

    /**
     * è®¡ç®—é¢éƒ¨åˆ†æç½®ä¿¡åº¦
     */
    private fun calculateFaceConfidence(faceData: FaceData, expression: FacialExpression): Float {
        var confidence = 0.8f  // é¢éƒ¨åˆ†æåŸºç¡€ç½®ä¿¡åº¦è¾ƒé«˜

        // æ£€æµ‹è´¨é‡
        faceData.detectionQuality?.let {
            confidence *= it
        }

        // ç‰¹å¾æ¸…æ™°åº¦
        val featureClarity = listOf(
            faceData.mouthOpen,
            faceData.eyebrowRaise,
            faceData.eyeSquint
        ).count { it != null && abs(it) > 0.1f } / 3f

        confidence *= (0.5f + featureClarity * 0.5f)

        // å¯¹ä¸­æ€§è¡¨æƒ…é™ä½ç½®ä¿¡åº¦ï¼ˆéš¾ä»¥åˆ¤æ–­ï¼‰
        if (expression == FacialExpression.NEUTRAL) {
            confidence *= 0.7f
        }

        return confidence.coerceIn(0f, 1f)
    }

    /**
     * è®¡ç®—æ¨¡æ€æƒé‡
     */
    private fun calculateModalityWeight(result: ModalityEmotionResult): Float {
        // åŸºäºç½®ä¿¡åº¦å’Œæ¨¡æ€ä¼˜å…ˆçº§
        val baseWeight = when (result.modality) {
            Modality.VOICE -> config.voiceWeight
            Modality.FACE -> config.faceWeight
            Modality.TEXT -> config.textWeight
        }

        return baseWeight * result.confidence
    }

    /**
     * è®¡ç®—èåˆç½®ä¿¡åº¦
     */
    private fun calculateFusedConfidence(modalityResults: List<ModalityEmotionResult>): Float {
        if (modalityResults.isEmpty()) return 0f

        // å¤šæ¨¡æ€ä¸€è‡´æ€§æ£€æŸ¥
        val valences = modalityResults.map { it.valence }
        val arousals = modalityResults.map { it.arousal }

        val valenceVariance = calculateVariance(valences)
        val arousalVariance = calculateVariance(arousals)

        // ä¸€è‡´æ€§åˆ†æ•°ï¼ˆæ–¹å·®è¶Šå°ï¼Œä¸€è‡´æ€§è¶Šé«˜ï¼‰
        val consistencyScore = 1f - (valenceVariance + arousalVariance) / 4f

        // å¹³å‡ç½®ä¿¡åº¦
        val avgConfidence = modalityResults.map { it.confidence }.average().toFloat()

        // èåˆç½®ä¿¡åº¦ = å¹³å‡ç½®ä¿¡åº¦ * ä¸€è‡´æ€§åˆ†æ•°
        return (avgConfidence * consistencyScore).coerceIn(0f, 1f)
    }

    /**
     * è®¡ç®—æ–¹å·®
     */
    private fun calculateVariance(values: List<Float>): Float {
        if (values.isEmpty()) return 0f
        val mean = values.average().toFloat()
        val squaredDiffs = values.map { (it - mean) * (it - mean) }
        return squaredDiffs.average().toFloat()
    }

    /**
     * æ˜ å°„åˆ°æƒ…æ„Ÿæ ‡ç­¾
     */
    private fun mapToEmotionLabel(valence: Float, arousal: Float): String {
        return when {
            valence > 0.3f && arousal > 0.6f -> "å…´å¥‹"   // é«˜æ¿€åŠ¨æ­£é¢
            valence > 0.3f && arousal <= 0.6f -> "å¹³é™å–œæ‚¦" // ä½æ¿€åŠ¨æ­£é¢
            valence < -0.3f && arousal > 0.6f -> "æ„¤æ€’/ææƒ§" // é«˜æ¿€åŠ¨è´Ÿé¢
            valence < -0.3f && arousal <= 0.6f -> "æ‚²ä¼¤" // ä½æ¿€åŠ¨è´Ÿé¢
            abs(valence) <= 0.3f && arousal > 0.6f -> "æƒŠè®¶" // ä¸­æ€§é«˜æ¿€åŠ¨
            else -> "ä¸­æ€§"                           // ä¸­æ€§ä½æ¿€åŠ¨
        }
    }

    /**
     * è®°å½•èåˆç»“æœ
     */
    private fun recordFusion(
        input: MultimodalInput,
        fusedEmotion: FusedEmotion,
        modalityResults: List<ModalityEmotionResult>
    ) {
        val record = FusionRecord(
            timestamp = LocalDateTime.now(),
            modalities = modalityResults.map { it.modality },
            fusedValence = fusedEmotion.valence,
            fusedArousal = fusedEmotion.arousal,
            fusedConfidence = fusedEmotion.confidence,
            emotionLabel = fusedEmotion.emotionLabel
        )

        _fusionHistory.value = (_fusionHistory.value + record).takeLast(100)

        _stats.value = _stats.value.copy(
            totalFusions = _stats.value.totalFusions + 1,
            voiceAnalysisCount = _stats.value.voiceAnalysisCount +
                    if (input.voiceData != null) 1 else 0,
            faceAnalysisCount = _stats.value.faceAnalysisCount +
                    if (input.faceData != null) 1 else 0,
            textAnalysisCount = _stats.value.textAnalysisCount +
                    if (input.textData != null) 1 else 0,
            averageConfidence = (
                _stats.value.averageConfidence * _stats.value.totalFusions + fusedEmotion.confidence
            ) / (_stats.value.totalFusions + 1),
            lastFusionTime = LocalDateTime.now()
        )
    }

    /**
     * æ›´æ–°é…ç½®
     */
    fun updateConfig(newConfig: FusionConfig) {
        config = newConfig
    }

    /**
     * è·å–å½“å‰é…ç½®
     */
    fun getConfig(): FusionConfig = config
}

// ========== æ•°æ®æ¨¡å‹ ==========

/**
 * å¤šæ¨¡æ€è¾“å…¥
 */
data class MultimodalInput(
    val voiceData: VoiceData? = null,
    val faceData: FaceData? = null,
    val textData: TextData? = null,
    val timestamp: LocalDateTime = LocalDateTime.now()
)

/**
 * è¯­éŸ³æ•°æ®
 */
data class VoiceData(
    val pitch: Float? = null,           // éŸ³è°ƒ (Hz)
    val volume: Float? = null,          // éŸ³é‡ (dB)
    val speed: Float? = null,           // è¯­é€Ÿ (å­—/ç§’)
    val jitter: Float? = null,          // å£°éŸ³é¢¤æŠ–åº¦ 0-1
    val signalQuality: Float? = null    // ä¿¡å·è´¨é‡ 0-1
)

/**
 * é¢éƒ¨æ•°æ®
 */
data class FaceData(
    val mouthOpen: Float? = null,        // å˜´å·´å¼ å¼€åº¦ 0-1
    val eyebrowRaise: Float? = null,     // çœ‰æ¯›ä¸Šæ‰¬åº¦ 0-1
    val eyeSquint: Float? = null,        // çœ¼ç›çœ¯ç¼åº¦ 0-1
    val mouthCornerUp: Float? = null,    // å˜´è§’ä¸Šæ‰¬åº¦ 0-1
    val mouthCornerDown: Float? = null,  // å˜´è§’ä¸‹å‚åº¦ 0-1
    val detectionQuality: Float? = null  // æ£€æµ‹è´¨é‡ 0-1
)

/**
 * æ–‡æœ¬æ•°æ®
 */
data class TextData(
    val content: String
)

/**
 * æ¨¡æ€ç±»å‹
 */
enum class Modality {
    VOICE,  // è¯­éŸ³
    FACE,   // é¢éƒ¨
    TEXT    // æ–‡æœ¬
}

/**
 * é¢éƒ¨è¡¨æƒ…
 */
enum class FacialExpression {
    HAPPY,      // å¼€å¿ƒ
    SAD,        // æ‚²ä¼¤
    ANGRY,      // æ„¤æ€’
    FEARFUL,    // ææƒ§
    SURPRISED,  // æƒŠè®¶
    DISGUSTED,  // åŒæ¶
    EXCITED,    // å…´å¥‹
    NEUTRAL     // ä¸­æ€§
}

/**
 * å•ä¸ªæ¨¡æ€çš„æƒ…æ„Ÿç»“æœ
 */
data class ModalityEmotionResult(
    val modality: Modality,
    val valence: Float,                // -1.0 ~ 1.0
    val arousal: Float,                // 0.0 ~ 1.0
    val confidence: Float,             // 0.0 ~ 1.0
    val rawFeatures: Map<String, Float>,
    val timestamp: LocalDateTime
)

/**
 * èåˆåçš„æƒ…æ„Ÿç»“æœ
 */
data class FusedEmotion(
    val valence: Float,                          // -1.0 ~ 1.0
    val arousal: Float,                          // 0.0 ~ 1.0
    val confidence: Float,                       // 0.0 ~ 1.0
    val emotionLabel: String,                    // æƒ…æ„Ÿæ ‡ç­¾
    val modalityCount: Int,                      // å‚ä¸èåˆçš„æ¨¡æ€æ•°é‡
    val modalityBreakdown: List<ModalityEmotionResult>,
    val timestamp: LocalDateTime
)

/**
 * èåˆé…ç½®
 */
data class FusionConfig(
    val voiceWeight: Float = 0.4f,      // è¯­éŸ³æƒé‡
    val faceWeight: Float = 0.4f,       // é¢éƒ¨æƒé‡
    val textWeight: Float = 0.2f,       // æ–‡æœ¬æƒé‡
    val minConfidenceThreshold: Float = 0.3f  // æœ€å°ç½®ä¿¡åº¦é˜ˆå€¼
)

/**
 * èåˆè®°å½•
 */
data class FusionRecord(
    val timestamp: LocalDateTime,
    val modalities: List<Modality>,
    val fusedValence: Float,
    val fusedArousal: Float,
    val fusedConfidence: Float,
    val emotionLabel: String
)

/**
 * èåˆç»Ÿè®¡
 */
data class FusionStats(
    val totalFusions: Int,
    val voiceAnalysisCount: Int,
    val faceAnalysisCount: Int,
    val textAnalysisCount: Int,
    val averageConfidence: Float,
    val lastFusionTime: LocalDateTime?
)