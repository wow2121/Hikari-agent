package com.xiaoguang.assistant.service.speech

import android.util.Log
import kotlinx.coroutines.flow.MutableStateFlow
import kotlinx.coroutines.flow.StateFlow
import kotlinx.coroutines.flow.asStateFlow
import javax.inject.Inject
import javax.inject.Singleton

/**
 * è¯­éŸ³æ´»åŠ¨æ£€æµ‹å™¨ï¼ˆVoice Activity Detectorï¼‰
 * ä½¿ç”¨è‡ªé€‚åº”é˜ˆå€¼ï¼Œæ ¹æ®ç¯å¢ƒå™ªå£°è‡ªåŠ¨è°ƒæ•´çµæ•åº¦
 */
@Singleton
class VoiceActivityDetector @Inject constructor() {
    companion object {
        private const val TAG = "VAD"

        // è‡ªé€‚åº”é˜ˆå€¼å‚æ•°
        private const val NOISE_FLOOR_INIT = 0.0003f  // åˆå§‹å™ªå£°åº•ï¼ˆé€‚åº” VOICE_RECOGNITION æºï¼‰
        private const val NOISE_FLOOR_ALPHA = 0.05f   // å™ªå£°åº•æ›´æ–°ç³»æ•°ï¼ˆè¶Šå°è¶Šå¹³æ»‘ï¼‰
        private const val SPEECH_THRESHOLD_RATIO = 2.5f  // è¯­éŸ³é˜ˆå€¼ = å™ªå£°åº• Ã— æ­¤å€æ•°
        private const val MIN_THRESHOLD = 0.0002f    // æœ€ä½é˜ˆå€¼ï¼Œé˜²æ­¢è¿‡äºæ•æ„Ÿ
        private const val MAX_THRESHOLD = 0.01f      // æœ€é«˜é˜ˆå€¼ï¼Œé˜²æ­¢è¿‡äºè¿Ÿé’

        // é›¶äº¤å‰ç‡é˜ˆå€¼
        private const val ZCR_THRESHOLD = 0.3f

        // è¿ç»­å¸§æ•°è¦æ±‚
        private const val MIN_SPEECH_FRAMES = 3
        private const val MIN_SILENCE_FRAMES = 10

        // åˆå§‹åŒ–å¸§æ•°ï¼ˆç”¨äºå­¦ä¹ ç¯å¢ƒå™ªå£°ï¼‰
        private const val INIT_FRAMES = 50
    }

    private val _isSpeechDetected = MutableStateFlow(false)
    val isSpeechDetected: StateFlow<Boolean> = _isSpeechDetected.asStateFlow()

    private var speechFrameCount = 0
    private var silenceFrameCount = 0
    private var lastEnergy = 0f  // æœ€åä¸€æ¬¡è®¡ç®—çš„èƒ½é‡å€¼

    // è‡ªé€‚åº”é˜ˆå€¼ç›¸å…³
    private var noiseFloor = NOISE_FLOOR_INIT  // å½“å‰å™ªå£°åº•ä¼°è®¡
    private var dynamicThreshold = NOISE_FLOOR_INIT * SPEECH_THRESHOLD_RATIO  // åŠ¨æ€é˜ˆå€¼
    private var initFrameCount = 0  // åˆå§‹åŒ–è®¡æ•°å™¨
    private var isInitialized = false  // æ˜¯å¦å®Œæˆåˆå§‹åŒ–

    /**
     * æ£€æµ‹éŸ³é¢‘å¸§æ˜¯å¦åŒ…å«è¯­éŸ³
     * @param audioData PCM 16ä½éŸ³é¢‘æ•°æ®
     * @return trueè¡¨ç¤ºæ£€æµ‹åˆ°è¯­éŸ³æ´»åŠ¨
     */
    fun detectVoiceActivity(audioData: ByteArray): Boolean {
        // è®¡ç®—èƒ½é‡
        val energy = calculateEnergy(audioData)
        lastEnergy = energy  // ä¿å­˜æœ€åä¸€æ¬¡çš„èƒ½é‡å€¼

        // è®¡ç®—é›¶äº¤å‰ç‡
        val zcr = calculateZeroCrossingRate(audioData)

        // åˆå§‹åŒ–é˜¶æ®µï¼šå­¦ä¹ ç¯å¢ƒå™ªå£°
        if (!isInitialized) {
            initFrameCount++
            // ä½¿ç”¨æŒ‡æ•°ç§»åŠ¨å¹³å‡æ›´æ–°å™ªå£°åº•
            noiseFloor = noiseFloor * (1 - NOISE_FLOOR_ALPHA) + energy * NOISE_FLOOR_ALPHA

            if (initFrameCount >= INIT_FRAMES) {
                isInitialized = true
                dynamicThreshold = (noiseFloor * SPEECH_THRESHOLD_RATIO).coerceIn(MIN_THRESHOLD, MAX_THRESHOLD)
                Log.i(TAG, "ğŸ¯ VAD åˆå§‹åŒ–å®Œæˆ: å™ªå£°åº•=${String.format("%.5f", noiseFloor)}, é˜ˆå€¼=${String.format("%.5f", dynamicThreshold)}")
            }

            frameCount++
            return false  // åˆå§‹åŒ–æœŸé—´ä¸æ£€æµ‹è¯­éŸ³
        }

        // è‡ªé€‚åº”æ›´æ–°å™ªå£°åº•ï¼ˆåªåœ¨é™éŸ³æ—¶æ›´æ–°ï¼‰
        if (!_isSpeechDetected.value && energy < dynamicThreshold) {
            noiseFloor = noiseFloor * (1 - NOISE_FLOOR_ALPHA * 0.1f) + energy * (NOISE_FLOOR_ALPHA * 0.1f)
            dynamicThreshold = (noiseFloor * SPEECH_THRESHOLD_RATIO).coerceIn(MIN_THRESHOLD, MAX_THRESHOLD)
        }

        // åˆ¤æ–­æ˜¯å¦ä¸ºè¯­éŸ³ï¼ˆä½¿ç”¨åŠ¨æ€é˜ˆå€¼ï¼‰
        val isSpeech = energy > dynamicThreshold && zcr < ZCR_THRESHOLD

        // è°ƒè¯•ï¼šå®šæœŸè¾“å‡ºèƒ½é‡å’Œé˜ˆå€¼
        if (frameCount % 100 == 0L) {
            Log.d(TAG, "[VAD] èƒ½é‡: ${String.format("%.5f", energy)} (é˜ˆå€¼: ${String.format("%.5f", dynamicThreshold)}, å™ªå£°åº•: ${String.format("%.5f", noiseFloor)}), ZCR: ${String.format("%.3f", zcr)}, è¯­éŸ³: $isSpeech")
        }
        frameCount++

        // å¹³æ»‘å¤„ç†ï¼šéœ€è¦è¿ç»­æ£€æµ‹åˆ°è¯­éŸ³/é™éŸ³æ‰æ”¹å˜çŠ¶æ€
        if (isSpeech) {
            speechFrameCount++
            silenceFrameCount = 0

            if (!_isSpeechDetected.value && speechFrameCount >= MIN_SPEECH_FRAMES) {
                _isSpeechDetected.value = true
                Log.i(TAG, "ğŸ¤ æ£€æµ‹åˆ°è¯­éŸ³æ´»åŠ¨ (èƒ½é‡: ${String.format("%.5f", energy)}, é˜ˆå€¼: ${String.format("%.5f", dynamicThreshold)})")
            }
        } else {
            silenceFrameCount++
            speechFrameCount = 0

            if (_isSpeechDetected.value && silenceFrameCount >= MIN_SILENCE_FRAMES) {
                _isSpeechDetected.value = false
                Log.i(TAG, "ğŸ”‡ è¯­éŸ³æ´»åŠ¨ç»“æŸ")
            }
        }

        return _isSpeechDetected.value
    }

    private var frameCount = 0L  // å¸§è®¡æ•°å™¨ï¼Œç”¨äºè°ƒè¯•æ—¥å¿—

    /**
     * è®¡ç®—éŸ³é¢‘èƒ½é‡
     */
    private fun calculateEnergy(audioData: ByteArray): Float {
        var sum = 0.0
        var count = 0

        for (i in audioData.indices step 2) {
            if (i + 1 < audioData.size) {
                val sample = ((audioData[i + 1].toInt() shl 8) or (audioData[i].toInt() and 0xFF)).toShort()
                val normalized = sample / 32768.0
                sum += normalized * normalized
                count++
            }
        }

        return if (count > 0) {
            kotlin.math.sqrt(sum / count).toFloat()
        } else {
            0f
        }
    }

    /**
     * è®¡ç®—é›¶äº¤å‰ç‡ï¼ˆZero Crossing Rateï¼‰
     * è¯­éŸ³ä¿¡å·çš„é›¶äº¤å‰ç‡é€šå¸¸è¾ƒä½ï¼Œå™ªå£°è¾ƒé«˜
     */
    private fun calculateZeroCrossingRate(audioData: ByteArray): Float {
        var zeroCrossings = 0
        var previousSample: Short = 0

        for (i in audioData.indices step 2) {
            if (i + 1 < audioData.size) {
                val currentSample = ((audioData[i + 1].toInt() shl 8) or (audioData[i].toInt() and 0xFF)).toShort()

                if (i > 0) {
                    if ((previousSample >= 0 && currentSample < 0) ||
                        (previousSample < 0 && currentSample >= 0)) {
                        zeroCrossings++
                    }
                }

                previousSample = currentSample
            }
        }

        val frameCount = audioData.size / 2
        return if (frameCount > 0) {
            zeroCrossings.toFloat() / frameCount
        } else {
            0f
        }
    }

    /**
     * è·å–æœ€åä¸€æ¬¡è®¡ç®—çš„èƒ½é‡å€¼
     */
    fun getLastEnergy(): Float {
        return lastEnergy
    }

    /**
     * é‡ç½®çŠ¶æ€
     */
    fun reset() {
        _isSpeechDetected.value = false
        speechFrameCount = 0
        silenceFrameCount = 0
        lastEnergy = 0f

        // é‡ç½®è‡ªé€‚åº”çŠ¶æ€
        noiseFloor = NOISE_FLOOR_INIT
        dynamicThreshold = NOISE_FLOOR_INIT * SPEECH_THRESHOLD_RATIO
        initFrameCount = 0
        isInitialized = false
        frameCount = 0L

        Log.d(TAG, "VAD å·²é‡ç½®ï¼Œå°†é‡æ–°å­¦ä¹ ç¯å¢ƒå™ªå£°")
    }
}
